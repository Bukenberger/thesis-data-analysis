{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vec_distance(df):\n",
    "    # Find the average distance between the left and right eye direction vectors\n",
    "    x1_coords = []\n",
    "    y1_coords = []\n",
    "    z1_coords = []\n",
    "\n",
    "    x2_coords = []\n",
    "    y2_coords = []\n",
    "    z2_coords = []\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        x1_coords.append(row['leftGazeRayDirectionX'])\n",
    "        y1_coords.append(row['leftGazeRayDirectionY'])\n",
    "        z1_coords.append(row['leftGazeRayDirectionZ'])\n",
    "\n",
    "        x2_coords.append(row['rightGazeRayDirectionX'])\n",
    "        y2_coords.append(row['rightGazeRayDirectionY'])\n",
    "        z2_coords.append(row['rightGazeRayDirectionZ'])\n",
    "\n",
    "    p1 = np.array([x1_coords, y1_coords, z1_coords])\n",
    "    p2 = np.array([x2_coords, y2_coords, z2_coords])\n",
    "\n",
    "    squared_dist = np.sum((p1-p2)**2, axis=0)\n",
    "    dist = np.sqrt(squared_dist)\n",
    "\n",
    "    # Remove extreme outliers using IQR\n",
    "    q75, q25 = np.percentile( dist, [75, 25] )\n",
    "    iqr = q75 - q25\n",
    "    cut_off = iqr * 1.5\n",
    "    lower_bound, upper_bound = q25 - cut_off, q75 + cut_off\n",
    "    \n",
    "    outliers = []\n",
    "    indices = []\n",
    "    for i in range(0, len(dist)):\n",
    "        if (dist[i] < lower_bound) or (dist[i] > upper_bound):\n",
    "            outliers.append(dist[i])\n",
    "            indices.append(i)\n",
    "\n",
    "    new_dist = np.delete(dist, indices)\n",
    "    new_times = df['milliTimestamp'].drop(index=indices).values\n",
    "    avg_dist = np.average(new_dist)\n",
    "    print(f\"Average distance: {avg_dist}\")\n",
    "\n",
    "    d = { 'distance': new_dist, 'time': new_times }\n",
    "    ax = sns.lineplot(data=d, x='time', y='distance')\n",
    "    ax.set_title(\"Distance Between Left and Right Eye Gaze\")\n",
    "    ax.set_xlabel(\"Time (Milliseconds)\")\n",
    "    ax.set_ylabel(\"Distance\")\n",
    "    ax.set_ylim(0,0.2)\n",
    "    plt.savefig(f\"left_right_eye_gaze_distance_plot_teran.png\", bbox_inches='tight', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECORDING_FOLDER_PATH = \"../Recordings/\"\n",
    "\n",
    "def label_saccades( eye_data_json, supervised_saccades_txt, id ) -> pd.DataFrame:\n",
    "    df = pd.read_json( f'{RECORDING_FOLDER_PATH}{eye_data_json}' )\n",
    "    df.insert( 0, \"id\", id )\n",
    "    df.insert( 0, \"isSaccade\", 0 )\n",
    "    txt = open( f'{RECORDING_FOLDER_PATH}{supervised_saccades_txt}' )\n",
    "    for line in txt:\n",
    "        line = line.rstrip().split(':')\n",
    "        lower_bound = int( line[0] )\n",
    "        upper_bound = int( line[1] )\n",
    "        df.loc[ (df.microTimestamp >= lower_bound) & (df.microTimestamp <= upper_bound), 'isSaccade' ] = 1\n",
    "\n",
    "    # Remove all invalid rows\n",
    "    df = df[df['gazeRayIsValid'] & df['rightGazeRayIsValid'] & df['leftGazeRayIsValid']]\n",
    "    df = df.reset_index()\n",
    "    return df\n",
    "\n",
    "df1 = label_saccades( \"jess-recording-1.json\", \"jess-saccades-1.txt\", 0 )\n",
    "df2 = label_saccades( \"jess-recording-2.json\", \"jess-saccades-2.txt\", 0 )\n",
    "df3 = label_saccades( \"teran-recording-1.json\", \"teran-saccades-1.txt\", 1 )\n",
    "df4 = label_saccades( \"luke-recording-1.json\", \"luke-saccades-1.txt\", 2 )\n",
    "df5 = label_saccades( \"luke-recording-2.json\", \"luke-saccades-1.txt\", 2 )\n",
    "\n",
    "# df = df1 # Jess\n",
    "# df = df2 # Jess\n",
    "df = df3 # Teran\n",
    "# df = df4 # Luke\n",
    "# df = df5 # Luke\n",
    "saccade_list = df['isSaccade']\n",
    "\n",
    "# plot_vec_distance(df)\n",
    "\n",
    "df = df.drop(\n",
    "        columns=[\n",
    "            'systemTimestamp',\n",
    "            'deviceTimestamp',\n",
    "            'microTimestamp',\n",
    "            'milliTimestamp',\n",
    "            'secTimestamp',\n",
    "            'minTimestamp',\n",
    "            \"isSaccade\",\n",
    "            \"id\",\n",
    "            'leftGazeRayIsValid',\n",
    "            'leftEyeIsBlinking',\n",
    "            'leftPupilDiameterIsValid',\n",
    "            'leftPositionGuideIsValid',\n",
    "            'rightGazeRayIsValid',\n",
    "            'rightEyeIsBlinking',\n",
    "            'rightPupilDiameterIsValid',\n",
    "            'rightPositionGuideIsValid',\n",
    "            'gazeRayIsValid',\n",
    "            'convergenceDistanceIsValid'\n",
    "        ]\n",
    "    )\n",
    "\n",
    "df_left_eye = df.drop(\n",
    "        columns=[\n",
    "            'rightGazeRayDirectionX',\n",
    "            'rightGazeRayDirectionY',\n",
    "            'rightGazeRayDirectionZ',\n",
    "            'rightGazeRayOriginX',\n",
    "            'rightGazeRayOriginY',\n",
    "            'rightGazeRayOriginZ',\n",
    "            'rightPupilDiameter',\n",
    "            'rightPositionGuideX',\n",
    "            'rightPositionGuideY'\n",
    "        ]\n",
    "    )\n",
    "\n",
    "df_right_eye = df.drop(\n",
    "        columns=[\n",
    "            'leftGazeRayDirectionX',\n",
    "            'leftGazeRayDirectionY',\n",
    "            'leftGazeRayDirectionZ',\n",
    "            'leftGazeRayOriginX',\n",
    "            'leftGazeRayOriginY',\n",
    "            'leftGazeRayOriginZ',\n",
    "            'leftPupilDiameter',\n",
    "            'leftPositionGuideX',\n",
    "            'leftPositionGuideY'\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_plot(\n",
    "            coeff, labels, scale=1, colors=None, visible=None, ax=plt, arrow_size=0.5\n",
    "        ):\n",
    "            for i, label in enumerate(labels):\n",
    "                if visible is None or visible[i]:\n",
    "                    ax.arrow(\n",
    "                        0,\n",
    "                        0,\n",
    "                        coeff[i, 0] * scale,\n",
    "                        coeff[i, 1] * scale,\n",
    "                        head_width=arrow_size * scale,\n",
    "                        head_length=arrow_size * scale,\n",
    "                        color=\"#000\" if colors is None else colors[i],\n",
    "                    )\n",
    "                    ax.text(\n",
    "                        coeff[i, 0] * 1.15 * scale,\n",
    "                        coeff[i, 1] * 1.15 * scale,\n",
    "                        label,\n",
    "                        color=\"#000\" if colors is None else colors[i],\n",
    "                        ha=\"center\",\n",
    "                        va=\"center\",\n",
    "                    )\n",
    "def pca_plot(dataframe: pd.DataFrame, targets: pd.DataFrame, str_plot_name: str):\n",
    "    pipeline = Pipeline([(\"scaler\", StandardScaler()), (\"pca\", PCA(n_components=2)),])\n",
    "\n",
    "    pca_data = pd.DataFrame(\n",
    "        pipeline.fit_transform(dataframe),\n",
    "        columns=[\"PC1\", \"PC2\"],\n",
    "        index=dataframe.index,\n",
    "    )\n",
    "\n",
    "    pca_data['movementType'] = targets\n",
    "    pca_step = pipeline.steps[1][1]\n",
    "    loadings = pd.DataFrame(\n",
    "        pca_step.components_.T,\n",
    "        columns=[\"PC1\", \"PC2\"],\n",
    "        index=dataframe.columns,\n",
    "    )\n",
    "\n",
    "    g = sns.scatterplot(data=loadings, x=\"PC1\", y=\"PC2\", hue=dataframe.columns)\n",
    "    x = pca_step.explained_variance_ratio_[0]\n",
    "    y = pca_step.explained_variance_ratio_[1]\n",
    "\n",
    "    # Add variance explained\n",
    "    g.set_xlabel(f\"PC1 ({x*100:.2f} %)\")\n",
    "    g.set_ylabel(f\"PC2 ({y*100:.2f} %)\")\n",
    "    sns.move_legend(g, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "    plt.savefig(f\"{str_plot_name}.png\", bbox_inches='tight', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def run_pca_and_svm(df: pd.DataFrame, targets: pd.DataFrame, svm_file_name: str):\n",
    "    # Train and Test Data Seperation\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(df, targets, test_size=0.25, \n",
    "                                                        stratify=targets, random_state=30)\n",
    "\n",
    "    print (\"train feature shape: \", X_train.shape)\n",
    "    print (\"test feature shape: \", X_test.shape)\n",
    "\n",
    "    # For PCA, First Need to Scale the Data.  \n",
    "    scaler1 = StandardScaler()\n",
    "    scaler1.fit(df)\n",
    "    feature_scaled = scaler1.transform(df)\n",
    "\n",
    "    # Now Apply PCA\n",
    "    pca1 = PCA(n_components=4)\n",
    "    pca1.fit(feature_scaled)\n",
    "    feature_scaled_pca = pca1.transform(feature_scaled)\n",
    "    print(\"shape of the scaled and 'PCA'ed features: \", np.shape(feature_scaled_pca))\n",
    "\n",
    "    # Let's see the variance to see out of the \n",
    "    # 4 components which are contributing most \n",
    "\n",
    "    feat_var = np.var(feature_scaled_pca, axis=0)\n",
    "    feat_var_rat = feat_var/(np.sum(feat_var))\n",
    "\n",
    "    print (\"Variance Ratio of the 4 Principal Components Ananlysis: \", feat_var_rat)\n",
    "\n",
    "    feature_scaled_pca_X0 = feature_scaled_pca[:, 0]\n",
    "    feature_scaled_pca_X1 = feature_scaled_pca[:, 1]\n",
    "    feature_scaled_pca_X2 = feature_scaled_pca[:, 2]\n",
    "    feature_scaled_pca_X3 = feature_scaled_pca[:, 3]\n",
    "\n",
    "    labels = targets\n",
    "    colordict = {0:'brown', 1:'darkslategray'}\n",
    "    piclabel = {0:'Not Saccade', 1:'Saccade'}\n",
    "    markers = {0:'o', 1:'*'}\n",
    "    alphas = {0:0.3, 1:0.4}\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 7))\n",
    "    plt.subplot(1,2,1)\n",
    "    for l in np.unique(labels):\n",
    "        ix = np.where(labels==l)\n",
    "        plt.scatter(feature_scaled_pca_X0[ix], feature_scaled_pca_X1[ix], c=colordict[l], \n",
    "                label=piclabel[l], s=40, marker=markers[l], alpha=alphas[l])\n",
    "    plt.xlabel(\"First Principal Component\", fontsize=15)\n",
    "    plt.ylabel(\"Second Principal Component\", fontsize=15)\n",
    "\n",
    "    plt.legend(fontsize=15)\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    for l1 in np.unique(labels):\n",
    "        ix1 = np.where(labels==l1)\n",
    "        plt.scatter(feature_scaled_pca_X2[ix1], feature_scaled_pca_X3[ix1], c=colordict[l1], \n",
    "                label=piclabel[l1], s=40, marker=markers[l1], alpha=alphas[l1])\n",
    "    plt.xlabel(\"Third Principal Component\", fontsize=15)\n",
    "    plt.ylabel(\"Fourth Principal Component\", fontsize=15)\n",
    "\n",
    "    plt.legend(fontsize=15)\n",
    "\n",
    "    plt.savefig('Saccade_labels_PCAs.png', dpi=200)\n",
    "    # plt.show()\n",
    "\n",
    "    # Pipeline Steps are StandardScaler, PCA and SVM \n",
    "    pipe_steps = [('scaler', StandardScaler()), ('pca', PCA()), ('SupVM', SVC(kernel='rbf'))]\n",
    "\n",
    "    check_params= {\n",
    "        'pca__n_components': [2], \n",
    "        'SupVM__C': [0.1, 0.5, 1, 10,30, 40, 50, 75, 100, 500, 1000], \n",
    "        'SupVM__gamma' : [0.01, 0.05, 0.07, 0.1, 0.5, 1, 5, 10, 50]\n",
    "    }\n",
    "\n",
    "    pipeline = Pipeline(pipe_steps)\n",
    "\n",
    "    from tqdm import tqdm_notebook as tqdm\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    print (\"Start Fitting Training Data\")\n",
    "    for cv in tqdm(range(4,6)):\n",
    "        create_grid = GridSearchCV(pipeline, param_grid=check_params, cv=cv)\n",
    "        create_grid.fit(X_train, Y_train)\n",
    "        print (\"score for %d fold CV := %3.2f\" %(cv, create_grid.score(X_test, Y_test)))\n",
    "        print (\"!!!!!!!! Best-Fit Parameters From Training Data !!!!!!!!!!!!!!\")\n",
    "        print (create_grid.best_params_)\n",
    "\n",
    "    print (\"out of the loop\")\n",
    "\n",
    "    print (\"grid best params: \", create_grid.best_params_) \n",
    "    # use the best one\n",
    "\n",
    "    # Time for Prediction and Plotting Confusion Matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import seaborn as sns\n",
    "\n",
    "    Y_pred = create_grid.predict(X_test)\n",
    "    # print (Y_pred)\n",
    "    cm = confusion_matrix(Y_test, Y_pred)\n",
    "    print(\"Confusion Matrix: \\n\")\n",
    "    print(cm)\n",
    "\n",
    "\n",
    "    df_cm = pd.DataFrame(cm, range(2), range(2))\n",
    "\n",
    "    sns.heatmap(df_cm, annot=True, cbar=False)\n",
    "    plt.title(\"Confusion Matrix\", fontsize=14)\n",
    "    plt.savefig(\"Confusion Matrix.png\", dpi=200)\n",
    "\n",
    "    # 2D Decision Boundary\n",
    "\n",
    "    scaler1 = StandardScaler()\n",
    "    scaler1.fit(X_test)\n",
    "    X_test_scaled = scaler1.transform(X_test)\n",
    "\n",
    "\n",
    "    pca2 = PCA(n_components=2)\n",
    "    X_test_scaled_reduced = pca2.fit_transform(X_test_scaled)\n",
    "\n",
    "\n",
    "    # svm_model = SVC(kernel='rbf', C=float(create_grid.best_params_['SupVM__C']), \n",
    "    #                 gamma=float(create_grid.best_params_['SupVM__gamma']))\n",
    "\n",
    "    svm_model = SVC(kernel='rbf', C=1., gamma=0.5)\n",
    "\n",
    "    classify = svm_model.fit(X_test_scaled_reduced, Y_test)\n",
    "\n",
    "    def plot_contours(ax, clf, xx, yy, **params):\n",
    "        Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "        print ('initial decision function shape; ', np.shape(Z))\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        print ('after reshape: ', np.shape(Z))\n",
    "        out = ax.contourf(xx, yy, Z, **params)\n",
    "        return out\n",
    "\n",
    "    def make_meshgrid(x, y, h=.1):\n",
    "        x_min, x_max = x.min() - 1, x.max() + 1\n",
    "        y_min, y_max = y.min() - 1, y.max() + 1\n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                            np.arange(y_min, y_max, h))#,\n",
    "                            #np.arange(z_min, z_max, h))\n",
    "        return xx, yy\n",
    "\n",
    "    X0, X1 = X_test_scaled_reduced[:, 0], X_test_scaled_reduced[:, 1]\n",
    "    xx, yy = make_meshgrid(X0, X1)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12,9))\n",
    "    fig.patch.set_facecolor('white')\n",
    "    cdict1={0:'lime',1:'deeppink'}\n",
    "\n",
    "    Y_tar_list = Y_test.tolist()\n",
    "    yl1= [int(target1) for target1 in Y_tar_list]\n",
    "    labels1=yl1\n",
    "    \n",
    "    labl1={0:'Saccade',1:'Not Saccade'}\n",
    "    marker1={0:'*',1:'d'}\n",
    "    alpha1={0:.8, 1:0.5}\n",
    "\n",
    "    for l1 in np.unique(labels1):\n",
    "        ix1=np.where(labels1==l1)\n",
    "        ax.scatter(X0[ix1],X1[ix1], c=cdict1[l1],label=labl1[l1],s=70,marker=marker1[l1],alpha=alpha1[l1])\n",
    "\n",
    "    ax.scatter(svm_model.support_vectors_[:, 0], svm_model.support_vectors_[:, 1], s=40, facecolors='none', \n",
    "            edgecolors='navy', label='Support Vectors')\n",
    "\n",
    "    plot_contours(ax, classify, xx, yy,cmap='seismic', alpha=0.4)\n",
    "    plt.legend(fontsize=15)\n",
    "\n",
    "    plt.xlabel(\"1st Principal Component\",fontsize=14)\n",
    "    plt.ylabel(\"2nd Principal Component\",fontsize=14)\n",
    "\n",
    "    \n",
    "    plt.savefig(f'{svm_file_name}.png', dpi=300)\n",
    "    # plt.savefig('ClassifySaccade_NotSaccade2D_Decs_FunctG10.png', dpi=300)\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_plot(df_left_eye, saccade_list, \"2D_PCA_with_loadings_left_eye\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_plot(df_right_eye, saccade_list, \"2D_PCA_with_loadings_right_eye\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_plot(df, saccade_list, \"2D_PCA_with_loadings_teran\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_plot(df, saccade_list, \"2D_PCA_with_loadings_jess\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_plot(df, saccade_list, \"2D_PCA_with_loadings_luke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_pca_and_svm(df_left_eye, saccade_list, \"ClassifySaccade_NotSaccade2D_Teran_left_eye\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_pca_and_svm(df_right_eye, saccade_list, \"ClassifySaccade_NotSaccade2D_Teran_right_eye\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_pca_and_svm(df, saccade_list, \"ClassifySaccade_NotSaccade2D_Teran_both_eyes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
